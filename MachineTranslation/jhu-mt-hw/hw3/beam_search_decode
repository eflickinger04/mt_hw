import heapq
import sys
import models
import math
from collections import namedtuple

class Hypothesis:
    def __init__(self, score, seq_translated, source_parts_translated, end, heuristic=0):
        self.score = score
        self.heuristic = heuristic
        if source_parts_translated is None:
            self.source_parts_translated = []
        else:
            self.source_parts_translated = source_parts_translated
        if seq_translated is None:
            self.seq_translated = []
        else:
            self.seq_translated = seq_translated
        self.end = end

    def total_cost(self):

        return self.score + self.heuristic


    def __lt__(self, other):
        return self.total_cost() < other.total_cost()

def calculate_heuristic(untranslated_parts):

    return untranslated_parts.count(0)

def a_star_decoder(french, tm, lm, beam_width, threshold):

    initial_h = Hypothesis(score=0.0, seq_translated=[], source_parts_translated=[0] * len(french), end=0, heuristic=len(french))
    lm_initial_state = ('<s>',)
    pq = [(initial_h.total_cost(), initial_h, lm_initial_state)]  # Priority queue based on total cost

    while pq:
        _, h, current_lm_state = heapq.heappop(pq)

        if all(h.source_parts_translated):
            return h.seq_translated

        for i in range(len(french)):
            for j in range(i + 1, len(french) + 1):
                if sum(h.source_parts_translated[i:j]) == 0:
                    phrase = tuple(french[i:j])
                    if phrase in tm:
                        translations = tm[phrase]
                        for translation, phrase_probability in translations:
                            new_source_parts_translated = h.source_parts_translated.copy()
                            for k in range(i, j):
                                new_source_parts_translated[k] = 1
                            if phrase_probability > 0:
                                phrase_log_probability = math.log(phrase_probability)
                            else:
                                phrase_log_probability = -math.inf

                            # Look at the previously translated sequence
                            if h.seq_translated:
                                prev_word = (h.seq_translated[-1],)
                            else:
                                prev_word = ('<s>',)

                            translation_tokens = translation.split()
                            translation_tuple = tuple(translation_tokens)

                            if translation_tuple:
                                curr_word = translation_tuple[0]
                                try:
                                    new_lm_state, lm_score = lm.score(prev_word, (curr_word,))
                                except KeyError:
                                    new_lm_state = current_lm_state
                                    lm_score = -100.0 
                            else:
                                lm_score = 0.0
                                new_lm_state = current_lm_state

                            total_score = h.score + phrase_log_probability + lm_score
                            new_seq_translated = h.seq_translated + translation_tokens
                            new_end = j

                            # Calculate heuristic for the new hypothesis
                            heuristic = calculate_heuristic(new_source_parts_translated)
                            new_hypothesis = Hypothesis(
                                score=total_score,
                                seq_translated=new_seq_translated,
                                source_parts_translated=new_source_parts_translated,
                                end=new_end,
                                heuristic=heuristic
                            )

                            heapq.heappush(pq, (new_hypothesis.total_cost(), new_hypothesis, new_lm_state))

    return None

def main():
    input_file = sys.argv[1]
    output_file = sys.argv[2]
    tm = models.TM('data/tm', k=sys.maxsize)  
    lm = models.LM('data/lm')       


    with open(input_file, 'r') as f:
        french = [tuple(line.strip().split()) for line in f.readlines() if line.strip()]
    

    for word in set(sum(french, ())):
        if (word,) not in tm:
            tm[(word,)] = [models.phrase(word, 0.0)]


    with open(output_file, 'w') as output:
        for idx, sentence in enumerate(french, 1):
            translation = a_star_decoder(sentence, tm, lm, beam_width=5, threshold=0.85)
            translation_sentence = ' '.join(translation) if translation else ''
            output.write(translation_sentence + "\n")

if __name__ == "__main__":
    main()
