import sys
import models
import math
from collections import namedtuple
import heapq

class Hypothesis:
    def __init__(self, score, seq_translated, source_parts_translated, end):
        self.score = score
        self.seq_translated = seq_translated if seq_translated is not None else []
        self.source_parts_translated = source_parts_translated if source_parts_translated is not None else [0] * len(seq_translated)
        self.end = end

    def __lt__(self, other):
        return self.score < other.score

def heuristic(french, tm, lm, seq_translated, remaining_parts, current_pos, reordering_window):
    remaining_phrases = len([x for x in remaining_parts if x == 0])
    
    if remaining_phrases > 0:
        next_untranslated_pos = remaining_parts.index(0)
        reordering_penalty = abs(current_pos - next_untranslated_pos)
        if reordering_penalty > reordering_window:
            reordering_penalty *= 2  
    else:
        reordering_penalty = 0
    
    length_penalty = 0.1 * remaining_phrases
    
    return -length_penalty - reordering_penalty

def a_star_decoder(french, tm, lm, threshold=0.85, reordering_window=2, beam_size=5):
    pq = []

    initial_h = Hypothesis(score=0.0, seq_translated=[], source_parts_translated=[0] * len(french), end=0)
    lm_initial_state = ('<s>',)
    
    heapq.heappush(pq, (0.0, initial_h, lm_initial_state))
    
    while pq:
        pq = heapq.nsmallest(beam_size, pq)

        _, h, current_lm_state = heapq.heappop(pq)
        
        if sum(h.source_parts_translated) == len(french):
            return h.seq_translated
        
        for i in range(len(french)):
            for j in range(i + 1, len(french) + 1):
                if sum(h.source_parts_translated[i:j]) == 0: 
                    phrase = tuple(french[i:j])
                    if phrase in tm:
                        translations = tm[phrase]
                        for translation, phrase_probability in translations:
                            new_source_parts_translated = h.source_parts_translated.copy()
                            for k in range(i, j):
                                new_source_parts_translated[k] = 1
                            if phrase_probability > 0:
                                phrase_log_probability = math.log(phrase_probability)
                            else:
                                phrase_log_probability = -math.inf

                            if h.seq_translated:
                                prev_word = (h.seq_translated[-1],)
                            else:
                                prev_word = ('<s>',)

                            try:
                                current_lm_state, lm_log_prob = lm.score(current_lm_state, translation.split()[0])
                            except KeyError:
                                lm_log_prob = -0.1 

                            new_seq_translated = h.seq_translated + [translation]
                            new_score = h.score + phrase_log_probability + lm_log_prob
                            h_estimate = heuristic(french, tm, lm, new_seq_translated, new_source_parts_translated, i, reordering_window)
                            
                            new_hypothesis = Hypothesis(score=new_score, seq_translated=new_seq_translated,
                                                        source_parts_translated=new_source_parts_translated, end=j)
                            heapq.heappush(pq, (new_score + h_estimate, new_hypothesis, current_lm_state))
    
    return None

def main():
    import optparse
    optparser = optparse.OptionParser()
    optparser.add_option("-i", "--input", dest="input", default="data/input", help="File containing sentences to translate (default=data/input)")
    optparser.add_option("-t", "--translation-model", dest="tm", default="data/tm", help="File containing translation model (default=data/tm)")
    optparser.add_option("-l", "--language-model", dest="lm", default="data/lm", help="File containing ARPA-format language model (default=data/lm)")
    optparser.add_option("-n", "--num_sentences", dest="num_sents", default=sys.maxsize, type="int", help="Number of sentences to decode (default=no limit)")
    optparser.add_option("-k", "--translations-per-phrase", dest="k", default=1, type="int", help="Limit on number of translations to consider per phrase (default=1)")
    optparser.add_option("-w", "--reordering-window", dest="reordering_window", default=2, type="int", help="Limit on phrase reordering window (default=2)")
    optparser.add_option("-b", "--beam-size", dest="beam_size", default=5, type="int", help="Maximum beam size for pruning (default=5)")
    opts = optparser.parse_args()[0]
    
    tm = models.TM(opts.tm, opts.k)
    lm = models.LM(opts.lm)
    
    french_sentences = [tuple(line.strip().split()) for line in open(opts.input).readlines()[:opts.num_sents]]
    
    for word in set(sum(french_sentences, ())):
        if (word,) not in tm:
            tm[(word,)] = [models.phrase(word, 0.0)]
    
=    for french in french_sentences:
        translation = a_star_decoder(french, tm, lm, reordering_window=opts.reordering_window, beam_size=opts.beam_size)
        print(" ".join(translation))

if __name__ == "__main__":
    main()
