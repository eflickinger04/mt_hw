#!/usr/bin/env python
import optparse
import sys
import models
from collections import namedtuple
import heapq  # for beam search

# Set up options
optparser = optparse.OptionParser()
optparser.add_option("-i", "--input", dest="input", default="data/input", help="File containing sentences to translate (default=data/input)")
optparser.add_option("-t", "--translation-model", dest="tm", default="data/tm", help="File containing translation model (default=data/tm)")
optparser.add_option("-l", "--language-model", dest="lm", default="data/lm", help="File containing ARPA-format language model (default=data/lm)")
optparser.add_option("-n", "--num_sentences", dest="num_sents", default=sys.maxsize, type="int", help="Number of sentences to decode (default=no limit)")
optparser.add_option("-k", "--translations-per-phrase", dest="k", default=1, type="int", help="Limit on number of translations to consider per phrase (default=1)")
optparser.add_option("-s", "--beam-size", dest="s", default=5, type="int", help="Maximum beam size (default=5)")
optparser.add_option("-v", "--verbose", dest="verbose", action="store_true", default=False,  help="Verbose mode (default=off)")
opts = optparser.parse_args()[0]

# Load models and input
tm = models.TM(opts.tm, opts.k)
lm = models.LM(opts.lm)
french = [tuple(line.strip().split()) for line in open(opts.input).readlines()[:opts.num_sents]]

# TM should translate unknown words as-is with probability 1
for word in set(sum(french, ())):
    if (word,) not in tm:
        tm[(word,)] = [models.phrase(word, 0.0)]

# Define a hypothesis as a namedtuple
hypothesis = namedtuple("hypothesis", "logprob, lm_state, predecessor, phrase, coverage")

# Function to extract the full English sentence from a hypothesis
def extract_english(hyp):
    return "" if hyp.predecessor is None else f"{extract_english(hyp.predecessor)} {hyp.phrase}"

# Beam search decoding
for f in french:
    initial_hypothesis = hypothesis(0.0, lm.begin(), None, None, frozenset())  # initial hypothesis
    stacks = [{} for _ in range(len(f) + 1)]  # a list of stacks for each position in the French sentence
    stacks[0][lm.begin()] = initial_hypothesis  # add the initial hypothesis to the first stack
    
    for i, stack in enumerate(stacks[:-1]):
        for h in sorted(stack.values(), key=lambda h: -h.logprob)[:opts.s]:  # prune stack to top s hypotheses
            for j in range(i + 1, len(f) + 1):
                if frozenset(range(i, j)) <= h.coverage:  # check if this phrase has already been covered
                    continue
                if f[i:j] in tm:
                    for phrase in tm[f[i:j]]:
                        logprob = h.logprob + phrase.logprob
                        lm_state = h.lm_state
                        for word in phrase.english.split():
                            (lm_state, word_logprob) = lm.score(lm_state, word)
                            logprob += word_logprob
                        logprob += lm.end(lm_state) if j == len(f) else 0.0
                        new_hyp = hypothesis(logprob, lm_state, h, phrase.english, h.coverage.union(range(i, j)))
                        if lm_state not in stacks[j] or stacks[j][lm_state].logprob < new_hyp.logprob:
                            stacks[j][lm_state] = new_hyp

    # Get best hypothesis from the last stack
    winner = max(stacks[-1].values(), key=lambda h: h.logprob)
    print(extract_english(winner))
