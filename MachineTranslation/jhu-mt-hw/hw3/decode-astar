import heapq
import sys
import models  

class AStarDecoder:
    def __init__(self, tm, lm, beam_size=10):
        self.tm = tm  # Translation Model
        self.lm = lm  # Language Model
        self.beam_size = beam_size  # Beam size for pruning

    def heuristic(self, remaining_french):
        # Simplified heuristic: just use the length of the remaining sentence
        return len(remaining_french) * -1.0  # Arbitrary fixed cost per word

    def decode(self, french_sentence):
        # A* priority queue
        pq = []

        # Initial state: (log_prob, translation_so_far, french_pos, lm_state)
        initial_state = (0.0, "", 0, self.lm.begin())  # Start LM state
        heapq.heappush(pq, (0.0, initial_state))

        best_translation = None
        best_log_prob = float('-inf')

        # Debug: Track sentence processing
        print(f"Decoding sentence: {' '.join(french_sentence)}")

        iteration = 0  # To track iterations of the while loop
        while pq:
            # Keep the top `beam_size` elements in the priority queue
            pq = pq[:self.beam_size]

            current_cost, (log_prob, english_translation, french_pos, lm_state) = heapq.heappop(pq)
            iteration += 1
            
            # Debug: Track each iteration and the current log probability
            print(f"Iteration {iteration}: log_prob = {log_prob}, english_translation = '{english_translation}'")

            # If the whole sentence is translated, we are done
            if french_pos == len(french_sentence):
                if log_prob > best_log_prob:
                    best_translation = english_translation
                    best_log_prob = log_prob
                continue

            # Expand possible translations for the next phrase in the sentence
            for length in range(1, len(french_sentence) - french_pos + 1):
                french_phrase = tuple(french_sentence[french_pos:french_pos + length])
                if french_phrase not in self.tm:
                    continue

                # Get possible English translations and their TM probabilities
                for english_phrase, tm_log_prob in self.tm[french_phrase]:
                    # Convert the phrase into a tuple for LM scoring
                    english_phrase_tuple = tuple(english_phrase.split())

                    # Update LM state and compute new probability
                    new_lm_state = self.lm.score(lm_state, english_phrase_tuple)

                    # Use the log probability from LM
                    lm_log_prob = new_lm_state[1]

                    # Compute the new log probability
                    new_log_prob = log_prob + tm_log_prob + lm_log_prob

                    # Debug: Track progress for each phrase expansion
                    print(f"Expanding with phrase: '{english_phrase}', new translation='{english_translation + ' ' + english_phrase}', new_log_prob={new_log_prob}")

                    # Form the new translation and update position
                    new_english_translation = (english_translation + " " + english_phrase).strip()
                    new_french_pos = french_pos + length

                    # Compute heuristic for remaining French (simple fixed heuristic)
                    h_cost = self.heuristic(french_sentence[new_french_pos:])

                    # Push new state onto the queue
                    new_state = (new_log_prob, new_english_translation, new_french_pos, new_lm_state[0])  # State is the first element (empty tuple or updated state)
                    heapq.heappush(pq, (-(new_log_prob + h_cost), new_state))

        return best_translation if best_translation else "No valid translation found"

def main():
    # Check for correct usage
    if len(sys.argv) != 3:
        sys.stderr.write("Usage: python decode-astar <input_file> <output_file>\n")
        sys.exit(1)

    # Correct path for the TM and LM files
    tm = models.TM('data/tm', k=3)  # Ensure the correct path to 'tm' file
    lm = models.LM('data/lm')       # Ensure the correct path to 'lm' file

    # Read input French sentences
    input_file = sys.argv[1]
    output_file = sys.argv[2]
    with open(input_file, 'r') as f:
        sentences = [line.strip().split() for line in f.readlines()]

    # Initialize A* decoder with beam size
    decoder = AStarDecoder(tm, lm, beam_size=5)  # Set beam size to 5 for faster pruning

    # Open the output file and write translations
    with open(output_file, 'w') as output:
        for sentence in sentences:
            translation = decoder.decode(sentence)
            output.write(translation + "\n")
            # Debug: Completed translation for the sentence
            print(f"Completed translation for: {' '.join(sentence)}")

    print(f"Translations written to {output_file}")

if __name__ == "__main__":
    main()
