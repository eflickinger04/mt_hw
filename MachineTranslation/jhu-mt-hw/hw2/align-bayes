#!/usr/bin/env python
import optparse
import sys
from collections import defaultdict
import random

# Parse command-line options
optparser = optparse.OptionParser()
optparser.add_option("-d", "--data", dest="train", default="data/hansards", help="Data filename prefix (default=data)")
optparser.add_option("-e", "--english", dest="english", default="e", help="Suffix of English filename (default=e)")
optparser.add_option("-f", "--french", dest="french", default="f", help="Suffix of French filename (default=f)")
optparser.add_option("-n", "--num_sentences", dest="num_sents", default=1000, type="int", help="Number of sentences to use for training and alignment")
optparser.add_option("-i", "--iterations", dest="iterations", default=100, type="int", help="Number of Gibbs sampling iterations")
(opts, _) = optparser.parse_args()

# Load the data
f_data = "%s.%s" % (opts.train, opts.french)
e_data = "%s.%s" % (opts.train, opts.english)

sys.stderr.write("Loading data...\n")
bitext = [[sentence.strip().split() for sentence in pair] for pair in zip(open(f_data), open(e_data))][:opts.num_sents]
sys.stderr.write("Done\n")

# Initialize translation probabilities and alignment counts
translation_prob = defaultdict(lambda: defaultdict(lambda: 1.0))  # P(f|e)
counts = defaultdict(lambda: defaultdict(float))  # Keeps track of word counts
alignments = []  # Stores alignments for Gibbs sampling

# Initialize alignment randomly
sys.stderr.write("Initializing alignments...\n")
for (f, e) in bitext:
    sentence_alignment = []
    for j, f_j in enumerate(f):
        alignment = random.randint(0, len(e) - 1)  # Random initial alignment
        sentence_alignment.append(alignment)
    alignments.append(sentence_alignment)
sys.stderr.write("Initialization complete.\n")

# Gibbs Sampling for Bayesian Inference
sys.stderr.write("Running Gibbs sampling...\n")
for iteration in range(opts.iterations):
    sys.stderr.write(f"Iteration {iteration + 1}/{opts.iterations}...\n")
    for s, (f, e) in enumerate(bitext):
        sentence_alignment = alignments[s]
        for j, f_j in enumerate(f):
            # Exclude current alignment
            current_alignment = sentence_alignment[j]
            counts[e[current_alignment]][f_j] -= 1
            
            # Compute the alignment probabilities
            total_prob = 0.0
            alignment_probs = []
            for i, e_i in enumerate(e):
                prob = (counts[e_i][f_j] + 0.0001)  # Add small Dirichlet prior
                total_prob += prob
                alignment_probs.append(prob)
            
            # Sample a new alignment
            rand_prob = random.uniform(0, total_prob)
            cumulative_prob = 0.0
            for i, prob in enumerate(alignment_probs):
                cumulative_prob += prob
                if cumulative_prob > rand_prob:
                    sentence_alignment[j] = i
                    break

            # Update counts with new alignment
            counts[e[sentence_alignment[j]]][f_j] += 1
    
sys.stderr.write("Gibbs sampling complete.\n")

# Output alignments
sys.stderr.write("Outputting final alignments...\n")
for (f, e), sentence_alignment in zip(bitext, alignments):
    alignment_output = []
    for j, f_j in enumerate(f):
        alignment_output.append(f"{j}-{sentence_alignment[j]}")
    sys.stdout.write(" ".join(alignment_output) + "\n")
sys.stderr.write("Alignment complete.\n")
